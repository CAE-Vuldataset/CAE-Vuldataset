# Data package for "Towards Causal Deep Learning for Vulnerability Detection"

## Organization

Below is an annotated map of the package's organization.

```
.
├── Causality
│   ├── codebert...........................................CodeBERT model details
│   │   ├── code...........................................Source code for CodeBERT Vanilla and Causal model
│   │   └── README.md......................................ReadMe from the CodeBERT authors
│   ├── data_preprocess....................................Data processing and figure plotting
│   │   ├── create_deadcode_dataset_v1.py..................Used to preprocess data for API1 setting
│   │   ├── create_no_transform_data.py....................Used to preprocess data for all data
│   │   ├── create_spurious_dataset.py.....................Used to preprocess data for VAR1 setting
│   │   ├── example_finding.ipynb..........................Code for searching fig1 and fig2 example and plot the data
│   │   ├── probability_density_vanilla_vs_causal.ipynb....Used to draw figure 6
│   │   ├── probability_density_k_1_vs_40.ipynb............Used to draw figure 7
│   │   ├── stats_sig_test.ipynb...........................Used to calculate the statistical significant test
│   │   └── utils.py.......................................An utility file, which is used in create_deadecode_dataset_v1.py
│   ├── GraphCodeBERT......................................GraphCodeBERT model details
│   │   ├── code...........................................Source code for GraphCodeBERT Vanilla and Causal model
│   │   ├── gcb_parser.....................................gcb parser utilities used in GraphCodeBERT default settings
│   │   └── README.md......................................ReadMe from the GraphCodeBERT authors.
│   ├── jobs...............................................Scripts to train and test the models
│   ├── NatGen.............................................Used to perturbed data in causal settings
│   └── UniXcoder..........................................UniXcoder model details
│       ├── code...........................................Source code for UniXcoder Vanilla and Causal model
│       └── README.md......................................ReadMe from UniXcoder authors
├── data...................................................All the input data to be stored here
│   ├── Devign.............................................Devign dataset
│   │   ├── train.jsonl....................................Train set in jsonl format
│   │   ├── test.jsonl.....................................Test set in jsonl format
│   │   └── valid.jsonl....................................Validation set in jsonl format
│   └── MSR................................................MSR or Big-Vul dataset dataset
│       ├── train.jsonl....................................Train set in jsonl format
│       ├── test.jsonl.....................................Test set in jsonl format
│       └── valid.jsonl....................................Validation set in jsonl format
├── discover-spurious......................................Section 3
│   ├── code...............................................Code for data creation for section 3.3 and robustness testing
│   ├── data...............................................Data for section 3
│   └── README.md..........................................ReadMe from the CodeBERT authors
├── README.md..............................................Overall README for the instructions
├── saved_models...........................................Model checkpoint should be saved here.
└── requirements.txt.......................................Required python packages to run the project

```

## Dataset overview

Dataset sources:
- Devign: https://drive.google.com/file/d/1x6hoF7G-tSYxg8AFybggypLZgMGDNHfF/view?usp=sharing
  - We used the canonical splits provided by the CodeXGLUE project (https://github.com/microsoft/CodeXGLUE/tree/main/Code-Code/Defect-detection).
- MSR: https://drive.google.com/file/d/1-0VhnHBp9IGh90s2wCNjeCMuy70HPl8X/view?usp=sharing
  - As Fan et al. does not provide canonical dataset splits, we used the same splits generated by the LineVul authors.

**MSR data is also known as Big-Vul data. In paper, we address it as Big-Vul data according to literature. But in our experiments we addressed it as MSR data**

## Data processing

We have created three set (train.json, test.jsonl and valid.jsonl) for both datasets.

To get these split set, follow the following steps:

- Goto data/ directory
- Unzip both Devign and MSR data

Now, before training or testing, do the following preprocessing

- Run the following script to process the data for setting Var1

	```
		cd Causality/data_preprocess
		python create_spurious_dataset.py --dataset Devign
	```
	This will add one key called $sp\_idx$ in each entry of the train.jsonl. The $sp\_idx$ is the 
	ids of examples which has maximum spurious name in common with the currecnt examples. The output will be saved as train_sp.jsonl in data/Devign directory. 

	Replace $Devign$ by $MSR$ to process the MSR data same way.

- run the following script to process the data for setting API1

	```
		cd Causality/data_preprocess
		python create_deadcode_dataset_v1.py Devign
	```
	This will add one key called $sp\_idx$ in each entry of the train.jsonl. The $sp\_idx$ is the 
	ids of examples which has maximum api in common with the currecnt examples. The output will be saved as train_dead_code.jsonl in data/Devign directory. 

	Replace $Devign$ to $MSR$ to process the MSR data same way.

- Now, run the following command to process every files using Natgen's no transform process

	```
		cd Causality/data_preprocess
		python create_no_transform_data.py --dataset Devign --src train.jsonl --des train_no_transform.jsonl
		python create_no_transform_data.py --dataset Devign --src test.jsonl --des test_no_transform.jsonl
		python create_no_transform_data.py --dataset Devign --src valid.jsonl --des valid_no_transform.jsonl
		python create_no_transform_data.py --dataset Devign --src train_sp.jsonl --des train_no_transform_with_xp.jsonl
		python create_no_transform_data.py --dataset Devign --src train_dead_code.jsonl --des train_no_transform_dead_code_with_xp.jsonl
	```

## Training and Evaluation

To train and evalaute any model aganist any test data run the following scripts:

- For vanilla model:
	```
		cd jobs
		bash causality_trainer_vanilla.sh <model name> <tr> <Dataset> <test_data_file> --seed <seed> 
	```
	- Replace <model name> by codebert, GraphCodeBERT or UniXcoder
	- Replace <tr> by 1 for training, and 0 for evaluation
	- Replace <Dataset> by Devign or MSR
	- Replace <test_data_file> with the test data file name e.g. test_no_transform.jsonl or any data.

	**Without training any model, it can not be evaluated. So, before evaluation, each model must be trained individually**

- For Var1 or Var2 settings:
	```
		cd jobs
		bash causality_trainer_spname.sh <model name> B6 <V1 or V2> <tr> <Dataset> <test_data_file> <early_layer> --seed <seed> 
	```
	- Replace <V1 or V2> by V1 to train Var1 or by V2 to train Var2
	- set <early_layer> to 4 for all training and evaluation in RQ1 and RQ2

	**Before training Var1/Var2 with any model, the vanilla version of that model must be trained. Otherwise, Representation R could not be calculated**

- For API1, API2 and API3 settings:
	```
		cd jobs
		bash causality_trainer_deadcode.sh <model name> B6 <API> <tr> <Dataset> <test_data_file>  <early_layer> --seed <seed> 
	```
	- Replace \<API> by V1 to train API1, by V2 to train API2 or by V3 to train API3

	**Before training API1/API2/API3 with any model, the vanilla version of that model must be trained. Otherwise, Representation R could not be calculated**

- For Var+API3 settings:
	```
		cd jobs
		bash causality_trainer_combine.sh <model name> B6 V3 <tr> <Dataset> <test_data_file>  <early_layer> --seed <seed> 
	```

	**Before training combine setting with any model, the vanilla version of that model must be trained. Otherwise, Representation R could not be calculated**

**ALL the output and evaluation metric results will be saved in a file inside Causality/logs directory**

## Reproduction of RQ1:

- Run the evaulation by the above commands by replacing <test_data_file> with test_no_transform.jsonl
- The output will be saved as a log file in a directory like
	```
	-Causality/logs/<model name>/<setting name>/<outputlog>.log
	```
	For different run for different settings, it will generate a different log file.

## Reproduction of RQ2:

- Run the evaulation by the above commands by replacing <test_data_file> with Generalization or robustness test file
- The output will be saved as a log file in Causality/logs/<model name>/<setting name>
- Details about robustness test data creation will be found at discover-spurious folder.
- For generalization, we can use devign test data on msr model and msr test data(excluding the FMPEG examples) to evaluate devign trained model.
	- Copy the msr test data into data/Devign folder by renaming
	- Do the similar thing for Devign test data
- We have provided the robustness data for Devign data  in the  data/Devign/robusntess folder for msr data in the data/MSR/robustnes folder
	- Before evaluating any file, move it to the data/Devign or data/MSR folder.
- We have provided the generalization data with the following name
	- data/Devign/test_no_transform_msr.jsonl
	- data/MSR/test_no_transform_devign.jsonl

**Data details are exaplained at data/README.md**
## Reproduction of RQ3:

For Early layer: 
	
	- Train and evaluate the model by setting <early_layer> to 1, 2, 3, 4.

For K=1:

	- We dont need to train or evaluate for K=1 separately.
	- During evaluation, the model evaluates for K=1 first, then evaluates for K=40.
	- The result for K=1 could be found at the very beginning of each of the log file 

## Reproduction of Section 3:

- All the perturbed datas will be found in discover-spurious/data directory. Before evaluating any data, move that data to
either data/Devign or data/MSR directory based on its origin dataset.

## Reproducing figures

- To reproduce the probability density plot between vanilla and causal model for figure 6, run the folloing notebook
	```
	data_preprocess/probability_density_vanilla_vs_causal.ipynb
	```
	The input of this notebook is automatically generated during testing

- To reproduce the probability density plot between K=1 and K=40 for figure 7, run the folloing notebook
	```
	data_preprocess/probability_density_k_1_vs_40.ipynb
	```
	The input of this notebook is automatically generated during testing
	
- To run the statistical significant test, use the following notebook
	```
	data_preprocess/stats_sig_test.ipynb
	```

## References

```
Devign dataset:
@article{zhou_devign_2019,
	title = {Devign: {Effective} vulnerability identification by learning comprehensive program semantics via graph neural networks},
	volume = {32},
	journal = {Advances in Neural Information Processing Systems},
	author = {Zhou, Yaqin and Liu, Shangqing and Siow, Jingkai and Du, Xiaoning and Liu, Yang},
	year = {2019},
	pages = {1--11},
	annote = {Graph NNFunction level},
}

MSR dataset:
@article{fan_cc_2020,
	title = {A {C}/{C}++ {Code} {Vulnerability} {Dataset} with {Code} {Changes} and {CVE} {Summaries}},
	issn = {9781450379571},
	doi = {10.1145/3379597.3387501},
	journal = {Proceedings - 2020 IEEE/ACM 17th International Conference on Mining Software Repositories, MSR 2020},
	author = {Fan, Jiahao and Li, Yi and Wang, Shaohua and Nguyen, Tien N.},
	year = {2020},
	keywords = {C/C++ Code, Code Changes, Common Vulnerabilities and Exposures},
	pages = {508--512},
}

```