{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 原始的patch\n",
    "# https://github.com/shuwang127/BinGNN/commit/137af4376381dec53bda56e6d01658ba9f3f2c55?diff=split\n",
    "# 重新生成的0-context patch\n",
    "# diff -0 -u  a/BinGNN.py b/BinGNN.py >p/BinGNN.py.patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['nodeidA1' 'BinGNN.py' 'funcname' 1 'import os\\n']\n",
      " ['nodeidA2' 'BinGNN.py' 'funcname' 2 'import sys\\n']\n",
      " ['nodeidA3' 'BinGNN.py' 'funcname' 3 'import time\\n']\n",
      " ['nodeidA4' 'BinGNN.py' 'funcname' 4 'import argparse\\n']\n",
      " ['nodeidA5' 'BinGNN.py' 'funcname' 5 'import numpy as np\\n']\n",
      " ['nodeidA6' 'BinGNN.py' 'funcname' 6 'import torch\\n']\n",
      " ['nodeidA7' 'BinGNN.py' 'funcname' 7\n",
      "  'from torch_geometric import __version__ as tg_version\\n']\n",
      " ['nodeidA8' 'BinGNN.py' 'funcname' 8\n",
      "  'from torch_geometric.loader import DataLoader\\n']\n",
      " ['nodeidA9' 'BinGNN.py' 'funcname' 9\n",
      "  'from libs.dataset import GetDataset\\n']\n",
      " ['nodeidA10' 'BinGNN.py' 'funcname' 10\n",
      "  '# from libs.graphvis import VisualGraph, VisualGraphs\\n']\n",
      " ['nodeidA11' 'BinGNN.py' 'funcname' 11\n",
      "  'from libs.utils import TrainTestSplit, OutputEval, SaveBestModel, EndEpochLoop\\n']\n",
      " ['nodeidA12' 'BinGNN.py' 'funcname' 12\n",
      "  'from libs.nets.BGNN_sliced import BGNN, BGNNTrain, BGNNTest\\n']\n",
      " ['nodeidA13' 'BinGNN.py' 'funcname' 13 '\\n']\n",
      " ['nodeidA14' 'BinGNN.py' 'funcname' 14 '# environment settings.\\n']\n",
      " ['nodeidA15' 'BinGNN.py' 'funcname' 15 \"rootPath = './'\\n\"]\n",
      " ['nodeidA16' 'BinGNN.py' 'funcname' 16 \"tempPath = './'\\n\"]\n",
      " ['nodeidA17' 'BinGNN.py' 'funcname' 17\n",
      "  \"dataPath = rootPath + '/data_np2/'\\n\"]\n",
      " ['nodeidA18' 'BinGNN.py' 'funcname' 18\n",
      "  \"logsPath = tempPath + '/logs/'\\n\"]\n",
      " ['nodeidA19' 'BinGNN.py' 'funcname' 19\n",
      "  \"mdlsPath = tempPath + '/models/'\\n\"]\n",
      " ['nodeidA20' 'BinGNN.py' 'funcname' 20 '# output parameters.\\n']\n",
      " ['nodeidA21' 'BinGNN.py' 'funcname' 21\n",
      "  '_DEBUG_  = 0    # 0: hide debug info. 1: show debug info.\\n']\n",
      " ['nodeidA22' 'BinGNN.py' 'funcname' 22\n",
      "  '_MODEL_  = 0    # 0: train new model. 1: use saved model.\\n']\n",
      " ['nodeidA23' 'BinGNN.py' 'funcname' 23 '# hyper-parameters.\\n']\n",
      " ['nodeidA24' 'BinGNN.py' 'funcname' 24 '_BATCHSIZE_ = 128\\n']\n",
      " ['nodeidA25' 'BinGNN.py' 'funcname' 25 '_MAXEPOCHS_ = 300\\n']\n",
      " ['nodeidA26' 'BinGNN.py' 'funcname' 26 '_LEARNRATE_ = 0.01\\n']\n",
      " ['nodeidA27' 'BinGNN.py' 'funcname' 27 '_TRAINRATE_ = 0.8\\n']\n",
      " ['nodeidA28' 'BinGNN.py' 'funcname' 28 '_WINDOWSIZ_ = 0\\n']\n",
      " ['nodeidA29' 'BinGNN.py' 'funcname' 29 '_FISTEPOCH_ = 0\\n']\n",
      " ['nodeidA30' 'BinGNN.py' 'funcname' 30 '\\n']\n",
      " ['nodeidA31' 'BinGNN.py' 'funcname' 31 '# global variable.\\n']\n",
      " ['nodeidA32' 'BinGNN.py' 'funcname' 32\n",
      "  'start_time = time.time() #mark start time\\n']\n",
      " ['nodeidA33' 'BinGNN.py' 'funcname' 33 '\\n']\n",
      " ['nodeidA34' 'BinGNN.py' 'funcname' 34\n",
      "  '# Logger: redirect the stream on screen and to file.\\n']\n",
      " ['nodeidA35' 'BinGNN.py' 'funcname' 35 'class Logger(object):\\n']\n",
      " ['nodeidA36' 'BinGNN.py' 'funcname' 36\n",
      "  '    def __init__(self, filename = \"log.txt\"):\\n']\n",
      " ['nodeidA37' 'BinGNN.py' 'funcname' 37\n",
      "  '        self.terminal = sys.stdout\\n']\n",
      " ['nodeidA38' 'BinGNN.py' 'funcname' 38\n",
      "  '        self.log = open(filename, \"a\")\\n']\n",
      " ['nodeidA39' 'BinGNN.py' 'funcname' 39 '    def write(self, message):\\n']\n",
      " ['nodeidA40' 'BinGNN.py' 'funcname' 40\n",
      "  '        self.terminal.write(message)\\n']\n",
      " ['nodeidA41' 'BinGNN.py' 'funcname' 41\n",
      "  '        self.log.write(message)\\n']\n",
      " ['nodeidA42' 'BinGNN.py' 'funcname' 42 '    def flush(self):\\n']\n",
      " ['nodeidA43' 'BinGNN.py' 'funcname' 43 '        pass\\n']\n",
      " ['nodeidA44' 'BinGNN.py' 'funcname' 44 '\\n']\n",
      " ['nodeidA45' 'BinGNN.py' 'funcname' 45 'def RunTime():\\n']\n",
      " ['nodeidA46' 'BinGNN.py' 'funcname' 46\n",
      "  \"    pTime = ' [TIME: ' + str(round((time.time() - start_time), 2)) + ' sec]'\\n\"]\n",
      " ['nodeidA47' 'BinGNN.py' 'funcname' 47 '    return pTime\\n']\n",
      " ['nodeidA48' 'BinGNN.py' 'funcname' 48 '\\n']\n",
      " ['nodeidA49' 'BinGNN.py' 'funcname' 49 'def main():\\n']\n",
      " ['nodeidA50' 'BinGNN.py' 'funcname' 50\n",
      "  '    # load the PatchCPG dataset.\\n']\n",
      " ['nodeidA51' 'BinGNN.py' 'funcname' 51\n",
      "  '    dataset = GetDataset(path=dataPath)  # get dataset from local dataset.\\n']\n",
      " ['nodeidA52' 'BinGNN.py' 'funcname' 52\n",
      "  '    # VisualGraphs(dataset[0], state=1)\\n']\n",
      " ['nodeidA53' 'BinGNN.py' 'funcname' 53 '\\n']\n",
      " ['nodeidA54' 'BinGNN.py' 'funcname' 54\n",
      "  '    # divide train set and test set.\\n']\n",
      " ['nodeidA55' 'BinGNN.py' 'funcname' 55\n",
      "  '    dataTrain, dataTest = TrainTestSplit(dataset, train_size=0.8, allow_shuffle=False)\\n']\n",
      " ['nodeidA56' 'BinGNN.py' 'funcname' 56\n",
      "  \"    print(f'[INFO] Number of training graphs: {len(dataTrain)}')\\n\"]\n",
      " ['nodeidA57' 'BinGNN.py' 'funcname' 57\n",
      "  \"    print(f'[INFO] Number of test graphs: {len(dataTest)}')\\n\"]\n",
      " ['nodeidA58' 'BinGNN.py' 'funcname' 58\n",
      "  \"    print(f'[INFO] Size of mini batch: {_BATCHSIZE_}')\\n\"]\n",
      " ['nodeidA59' 'BinGNN.py' 'funcname' 59\n",
      "  \"    print('[INFO] =============================================================')\\n\"]\n",
      " ['nodeidA60' 'BinGNN.py' 'funcname' 60\n",
      "  '    # get the train dataloader and test dataloader.\\n']\n",
      " ['nodeidA61' 'BinGNN.py' 'funcname' 61\n",
      "  \"    trainloader = DataLoader(dataTrain, batch_size=_BATCHSIZE_, follow_batch=['x_s', 'x_t'], shuffle=False)\\n\"]\n",
      " ['nodeidA62' 'BinGNN.py' 'funcname' 62\n",
      "  \"    testloader = DataLoader(dataTest, batch_size=_BATCHSIZE_, follow_batch=['x_s', 'x_t'], shuffle=False)\\n\"]\n",
      " ['nodeidA63' 'BinGNN.py' 'funcname' 63 '\\n']\n",
      " ['nodeidA64' 'BinGNN.py' 'funcname' 64\n",
      "  '    # demo for graph neural network.\\n']\n",
      " ['nodeidA65' 'BinGNN.py' 'funcname' 65\n",
      "  '    demo_BinGNN(trainloader, testloader, dim_features=len(dataset[0].x_s[0]))\\n']\n",
      " ['nodeidA66' 'BinGNN.py' 'funcname' 66 '\\n']\n",
      " ['nodeidA67' 'BinGNN.py' 'funcname' 67 '    return\\n']\n",
      " ['nodeidA68' 'BinGNN.py' 'funcname' 68 '\\n']\n",
      " ['nodeidA69' 'BinGNN.py' 'funcname' 69\n",
      "  'def demo_BinGNN(trainloader, testloader, dim_features):\\n']\n",
      " ['nodeidA70' 'BinGNN.py' 'funcname' 70\n",
      "  '    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\\n']\n",
      " ['nodeidA71' 'BinGNN.py' 'funcname' 71\n",
      "  '    model = BGNN(num_node_features=dim_features)\\n']\n",
      " ['nodeidA72' 'BinGNN.py' 'funcname' 72 '\\n']\n",
      " ['nodeidA73' 'BinGNN.py' 'funcname' 73\n",
      "  \"    if not (_MODEL_ and os.path.exists(mdlsPath + f'/model_BGNN_{dim_features}.pth')):\\n\"]\n",
      " ['nodeidA74' 'BinGNN.py' 'funcname' 74\n",
      "  '        # define optimizer, criterion.\\n']\n",
      " ['nodeidA75' 'BinGNN.py' 'funcname' 75\n",
      "  '        optimizer = torch.optim.Adam(model.parameters(), lr=_LEARNRATE_)\\n']\n",
      " ['nodeidA76' 'BinGNN.py' 'funcname' 76\n",
      "  '        criterion = torch.nn.CrossEntropyLoss()\\n']\n",
      " ['nodeidA77' 'BinGNN.py' 'funcname' 77\n",
      "  \"        print(f'[INFO] Optimizer settings:\\\\n{optimizer}')\\n\"]\n",
      " ['nodeidA78' 'BinGNN.py' 'funcname' 78\n",
      "  \"        print(f'[INFO] Criterion settings: {criterion}')\\n\"]\n",
      " ['nodeidA79' 'BinGNN.py' 'funcname' 79\n",
      "  \"        print(f'[INFO] Maximum epoch number: {_MAXEPOCHS_}')\\n\"]\n",
      " ['nodeidA80' 'BinGNN.py' 'funcname' 80\n",
      "  \"        print('[INFO] =============================================================')\\n\"]\n",
      " ['nodeidA81' 'BinGNN.py' 'funcname' 81 '        # train model.\\n']\n",
      " ['nodeidA82' 'BinGNN.py' 'funcname' 82\n",
      "  '        accList = [0]  # accuracy recorder.\\n']\n",
      " ['nodeidA83' 'BinGNN.py' 'funcname' 83\n",
      "  '        for epoch in range(1, _MAXEPOCHS_ + 1):\\n']\n",
      " ['nodeidA84' 'BinGNN.py' 'funcname' 84\n",
      "  '            # train model and evaluate model.\\n']\n",
      " ['nodeidA85' 'BinGNN.py' 'funcname' 85\n",
      "  '            model, loss = BGNNTrain(model, trainloader, optimizer=optimizer, criterion=criterion)\\n']\n",
      " ['nodeidA86' 'BinGNN.py' 'funcname' 86\n",
      "  '            trainAcc, trainPred, trainLabel = BGNNTest(model, trainloader)\\n']\n",
      " ['nodeidA87' 'BinGNN.py' 'funcname' 87\n",
      "  '            testAcc, testPred, testLabel = BGNNTest(model, testloader)\\n']\n",
      " ['nodeidA88' 'BinGNN.py' 'funcname' 88\n",
      "  \"            print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train Acc: {trainAcc:.4f}, Test Acc: {testAcc:.4f}')\\n\"]\n",
      " ['nodeidA89' 'BinGNN.py' 'funcname' 89\n",
      "  '            # save the best model.\\n']\n",
      " ['nodeidA90' 'BinGNN.py' 'funcname' 90\n",
      "  '            accList.append(testAcc)\\n']\n",
      " ['nodeidA91' 'BinGNN.py' 'funcname' 91\n",
      "  \"            SaveBestModel(accList, model, path=mdlsPath, modelname='BGNN', para=dim_features)\\n\"]\n",
      " ['nodeidA92' 'BinGNN.py' 'funcname' 92\n",
      "  '            # termination judgement.\\n']\n",
      " ['nodeidA93' 'BinGNN.py' 'funcname' 93\n",
      "  '            if (EndEpochLoop(accList, window=_WINDOWSIZ_, firstepoch=_FISTEPOCH_)): break\\n']\n",
      " ['nodeidA94' 'BinGNN.py' 'funcname' 94 '\\n']\n",
      " ['nodeidA95' 'BinGNN.py' 'funcname' 95\n",
      "  '        # evaluation with the best model.\\n']\n",
      " ['nodeidA96' 'BinGNN.py' 'funcname' 96\n",
      "  \"    model.load_state_dict(torch.load(mdlsPath + f'/model_BGNN_{dim_features}.pth'))\\n\"]\n",
      " ['nodeidA97' 'BinGNN.py' 'funcname' 97\n",
      "  '    testAcc, testPred, testLabel = BGNNTest(model, testloader)\\n']\n",
      " ['nodeidA98' 'BinGNN.py' 'funcname' 98\n",
      "  \"    OutputEval(testPred, testLabel, 'BGNN')\\n\"]\n",
      " ['nodeidA99' 'BinGNN.py' 'funcname' 99 '\\n']\n",
      " ['nodeidA100' 'BinGNN.py' 'funcname' 100 '    return \\n']\n",
      " ['nodeidA101' 'BinGNN.py' 'funcname' 101 '\\n']\n",
      " ['nodeidA102' 'BinGNN.py' 'funcname' 102 \"if __name__ == '__main__':\\n\"]\n",
      " ['nodeidA103' 'BinGNN.py' 'funcname' 103 '    # sparse the arguments.\\n']\n",
      " ['nodeidA104' 'BinGNN.py' 'funcname' 104\n",
      "  '    # initialize the log file.\\n']\n",
      " ['nodeidA105' 'BinGNN.py' 'funcname' 105 \"    logfile = f'BinGNN.txt'\\n\"]\n",
      " ['nodeidA106' 'BinGNN.py' 'funcname' 106\n",
      "  '    if os.path.exists(os.path.join(logsPath, logfile)):\\n']\n",
      " ['nodeidA107' 'BinGNN.py' 'funcname' 107\n",
      "  '        os.remove(os.path.join(logsPath, logfile))\\n']\n",
      " ['nodeidA108' 'BinGNN.py' 'funcname' 108\n",
      "  '    elif not os.path.exists(logsPath):\\n']\n",
      " ['nodeidA109' 'BinGNN.py' 'funcname' 109\n",
      "  '        os.makedirs(logsPath)\\n']\n",
      " ['nodeidA110' 'BinGNN.py' 'funcname' 110\n",
      "  '    sys.stdout = Logger(os.path.join(logsPath, logfile))\\n']\n",
      " ['nodeidA111' 'BinGNN.py' 'funcname' 111\n",
      "  '    # set torch environment.\\n']\n",
      " ['nodeidA112' 'BinGNN.py' 'funcname' 112\n",
      "  \"    print('[INFO] CUDA Version: ' + (torch.version.cuda if torch.version.cuda else 'None'))\\n\"]\n",
      " ['nodeidA113' 'BinGNN.py' 'funcname' 113\n",
      "  \"    print('[INFO] PyTorch Version: ' + torch.__version__)\\n\"]\n",
      " ['nodeidA114' 'BinGNN.py' 'funcname' 114\n",
      "  \"    print('[INFO] Pytorch-Geometric Version: ' + tg_version)\\n\"]\n",
      " ['nodeidA115' 'BinGNN.py' 'funcname' 115 '    # main entrance.\\n']\n",
      " ['nodeidA116' 'BinGNN.py' 'funcname' 116 '    main()']]\n"
     ]
    }
   ],
   "source": [
    "# read graph of A.\n",
    "lines = open('a/BinGNN.py', 'r').readlines()\n",
    "nodesA = np.array([['nodeidA'+str(linenum+1), 'BinGNN.py', 'funcname', linenum+1, lines[linenum]] for linenum in range(len(lines))], dtype=object)\n",
    "# edgesA = [[.., .., .., ..] ..]\n",
    "print(nodesA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['nodeidB1' 'BinGNN.py' 'funcname' 1 'import os\\n']\n",
      " ['nodeidB2' 'BinGNN.py' 'funcname' 2 'import sys\\n']\n",
      " ['nodeidB3' 'BinGNN.py' 'funcname' 3 'import time\\n']\n",
      " ['nodeidB4' 'BinGNN.py' 'funcname' 4 'import argparse\\n']\n",
      " ['nodeidB5' 'BinGNN.py' 'funcname' 5 'import numpy as np\\n']\n",
      " ['nodeidB6' 'BinGNN.py' 'funcname' 6 'import torch\\n']\n",
      " ['nodeidB7' 'BinGNN.py' 'funcname' 7\n",
      "  'from torch_geometric import __version__ as tg_version\\n']\n",
      " ['nodeidB8' 'BinGNN.py' 'funcname' 8\n",
      "  'from torch_geometric.loader import DataLoader\\n']\n",
      " ['nodeidB9' 'BinGNN.py' 'funcname' 9\n",
      "  'from libs.dataset import GetDataset\\n']\n",
      " ['nodeidB10' 'BinGNN.py' 'funcname' 10\n",
      "  '# from libs.graphvis import VisualGraph, VisualGraphs\\n']\n",
      " ['nodeidB11' 'BinGNN.py' 'funcname' 11\n",
      "  'from libs.utils import TrainTestSplit, OutputEval, SaveBestModel, EndEpochLoop\\n']\n",
      " ['nodeidB12' 'BinGNN.py' 'funcname' 12\n",
      "  'from libs.nets.BGNN_sliced import BGNN, BGNNTrain, BGNNTest\\n']\n",
      " ['nodeidB13' 'BinGNN.py' 'funcname' 13 '\\n']\n",
      " ['nodeidB14' 'BinGNN.py' 'funcname' 14 '# environment settings.\\n']\n",
      " ['nodeidB15' 'BinGNN.py' 'funcname' 15 \"rootPath = './'\\n\"]\n",
      " ['nodeidB16' 'BinGNN.py' 'funcname' 16 \"tempPath = './'\\n\"]\n",
      " ['nodeidB17' 'BinGNN.py' 'funcname' 17\n",
      "  \"dataPath = rootPath + '/data_np2/'\\n\"]\n",
      " ['nodeidB18' 'BinGNN.py' 'funcname' 18\n",
      "  \"logsPath = tempPath + '/logs/'\\n\"]\n",
      " ['nodeidB19' 'BinGNN.py' 'funcname' 19\n",
      "  \"mdlsPath = tempPath + '/models/'\\n\"]\n",
      " ['nodeidB20' 'BinGNN.py' 'funcname' 20 '# output parameters.\\n']\n",
      " ['nodeidB21' 'BinGNN.py' 'funcname' 21\n",
      "  '_DEBUG_  = 0    # 0: hide debug info. 1: show debug info.\\n']\n",
      " ['nodeidB22' 'BinGNN.py' 'funcname' 22\n",
      "  '_MODEL_  = 0    # 0: train new model. 1: use saved model.\\n']\n",
      " ['nodeidB23' 'BinGNN.py' 'funcname' 23 '# hyper-parameters.\\n']\n",
      " ['nodeidB24' 'BinGNN.py' 'funcname' 24 '_BATCHSIZE_ = 128\\n']\n",
      " ['nodeidB25' 'BinGNN.py' 'funcname' 25 '_MAXEPOCHS_ = 1000\\n']\n",
      " ['nodeidB26' 'BinGNN.py' 'funcname' 26 '_LEARNRATE_ = 0.01\\n']\n",
      " ['nodeidB27' 'BinGNN.py' 'funcname' 27 '_TRAINRATE_ = 0.8\\n']\n",
      " ['nodeidB28' 'BinGNN.py' 'funcname' 28 '_WINDOWSIZ_ = 0\\n']\n",
      " ['nodeidB29' 'BinGNN.py' 'funcname' 29 '_FISTEPOCH_ = 0\\n']\n",
      " ['nodeidB30' 'BinGNN.py' 'funcname' 30 '\\n']\n",
      " ['nodeidB31' 'BinGNN.py' 'funcname' 31 '# global variable.\\n']\n",
      " ['nodeidB32' 'BinGNN.py' 'funcname' 32\n",
      "  'start_time = time.time() #mark start time\\n']\n",
      " ['nodeidB33' 'BinGNN.py' 'funcname' 33 '\\n']\n",
      " ['nodeidB34' 'BinGNN.py' 'funcname' 34\n",
      "  '# Logger: redirect the stream on screen and to file.\\n']\n",
      " ['nodeidB35' 'BinGNN.py' 'funcname' 35 'class Logger(object):\\n']\n",
      " ['nodeidB36' 'BinGNN.py' 'funcname' 36\n",
      "  '    def __init__(self, filename = \"log.txt\"):\\n']\n",
      " ['nodeidB37' 'BinGNN.py' 'funcname' 37\n",
      "  '        self.terminal = sys.stdout\\n']\n",
      " ['nodeidB38' 'BinGNN.py' 'funcname' 38\n",
      "  '        self.log = open(filename, \"a\")\\n']\n",
      " ['nodeidB39' 'BinGNN.py' 'funcname' 39 '    def write(self, message):\\n']\n",
      " ['nodeidB40' 'BinGNN.py' 'funcname' 40\n",
      "  '        self.terminal.write(message)\\n']\n",
      " ['nodeidB41' 'BinGNN.py' 'funcname' 41\n",
      "  '        self.log.write(message)\\n']\n",
      " ['nodeidB42' 'BinGNN.py' 'funcname' 42 '    def flush(self):\\n']\n",
      " ['nodeidB43' 'BinGNN.py' 'funcname' 43 '        pass\\n']\n",
      " ['nodeidB44' 'BinGNN.py' 'funcname' 44 '\\n']\n",
      " ['nodeidB45' 'BinGNN.py' 'funcname' 45 'def RunTime():\\n']\n",
      " ['nodeidB46' 'BinGNN.py' 'funcname' 46\n",
      "  \"    pTime = ' [TIME: ' + str(round((time.time() - start_time), 2)) + ' sec]'\\n\"]\n",
      " ['nodeidB47' 'BinGNN.py' 'funcname' 47 '    return pTime\\n']\n",
      " ['nodeidB48' 'BinGNN.py' 'funcname' 48 '\\n']\n",
      " ['nodeidB49' 'BinGNN.py' 'funcname' 49 'def main():\\n']\n",
      " ['nodeidB50' 'BinGNN.py' 'funcname' 50\n",
      "  '    # load the PatchCPG dataset.\\n']\n",
      " ['nodeidB51' 'BinGNN.py' 'funcname' 51\n",
      "  '    dataset, filelist = GetDataset(path=dataPath)  # get dataset from local dataset.\\n']\n",
      " ['nodeidB52' 'BinGNN.py' 'funcname' 52\n",
      "  '    # VisualGraphs(dataset[0], state=1)\\n']\n",
      " ['nodeidB53' 'BinGNN.py' 'funcname' 53 '\\n']\n",
      " ['nodeidB54' 'BinGNN.py' 'funcname' 54\n",
      "  '    # divide train set and test set.\\n']\n",
      " ['nodeidB55' 'BinGNN.py' 'funcname' 55\n",
      "  '    dataTrain, dataTest = TrainTestSplit(dataset, train_size=_TRAINRATE_, allow_shuffle=False)\\n']\n",
      " ['nodeidB56' 'BinGNN.py' 'funcname' 56\n",
      "  '    fileTrain, fileTest = filelist[0:len(dataTrain)], filelist[len(dataTrain):]\\n']\n",
      " ['nodeidB57' 'BinGNN.py' 'funcname' 57\n",
      "  \"    print(f'[INFO] Number of training graphs: {len(dataTrain)}')\\n\"]\n",
      " ['nodeidB58' 'BinGNN.py' 'funcname' 58\n",
      "  \"    print(f'[INFO] Number of test graphs: {len(dataTest)}')\\n\"]\n",
      " ['nodeidB59' 'BinGNN.py' 'funcname' 59\n",
      "  \"    print(f'[INFO] Size of mini batch: {_BATCHSIZE_}')\\n\"]\n",
      " ['nodeidB60' 'BinGNN.py' 'funcname' 60\n",
      "  \"    print('[INFO] =============================================================')\\n\"]\n",
      " ['nodeidB61' 'BinGNN.py' 'funcname' 61\n",
      "  '    # get the train dataloader and test dataloader.\\n']\n",
      " ['nodeidB62' 'BinGNN.py' 'funcname' 62\n",
      "  \"    trainloader = DataLoader(dataTrain, batch_size=_BATCHSIZE_, follow_batch=['x_s', 'x_t'], shuffle=False)\\n\"]\n",
      " ['nodeidB63' 'BinGNN.py' 'funcname' 63\n",
      "  \"    testloader = DataLoader(dataTest, batch_size=_BATCHSIZE_, follow_batch=['x_s', 'x_t'], shuffle=False)\\n\"]\n",
      " ['nodeidB64' 'BinGNN.py' 'funcname' 64 '\\n']\n",
      " ['nodeidB65' 'BinGNN.py' 'funcname' 65\n",
      "  '    # demo for graph neural network.\\n']\n",
      " ['nodeidB66' 'BinGNN.py' 'funcname' 66\n",
      "  '    model = demo_BinGNN(trainloader, testloader, dim_features=len(dataset[0].x_s[0]))\\n']\n",
      " ['nodeidB67' 'BinGNN.py' 'funcname' 67\n",
      "  '    # output results on test data.\\n']\n",
      " ['nodeidB68' 'BinGNN.py' 'funcname' 68\n",
      "  '    _, testPred, _ = BGNNTest(model, testloader)\\n']\n",
      " ['nodeidB69' 'BinGNN.py' 'funcname' 69\n",
      "  \"    with open(logsPath + 'TestResults.txt', 'w') as f:\\n\"]\n",
      " ['nodeidB70' 'BinGNN.py' 'funcname' 70\n",
      "  '        for i in range(len(fileTest)):\\n']\n",
      " ['nodeidB71' 'BinGNN.py' 'funcname' 71\n",
      "  \"            f.write(fileTest[i] + ',' + str(testPred[i]) + '\\\\n')\\n\"]\n",
      " ['nodeidB72' 'BinGNN.py' 'funcname' 72 '\\n']\n",
      " ['nodeidB73' 'BinGNN.py' 'funcname' 73 '    return\\n']\n",
      " ['nodeidB74' 'BinGNN.py' 'funcname' 74 '\\n']\n",
      " ['nodeidB75' 'BinGNN.py' 'funcname' 75\n",
      "  'def demo_BinGNN(trainloader, testloader, dim_features):\\n']\n",
      " ['nodeidB76' 'BinGNN.py' 'funcname' 76\n",
      "  '    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\\n']\n",
      " ['nodeidB77' 'BinGNN.py' 'funcname' 77\n",
      "  '    model = BGNN(num_node_features=dim_features)\\n']\n",
      " ['nodeidB78' 'BinGNN.py' 'funcname' 78 '\\n']\n",
      " ['nodeidB79' 'BinGNN.py' 'funcname' 79\n",
      "  \"    if not (_MODEL_ and os.path.exists(mdlsPath + f'/model_BGNN_{dim_features}.pth')):\\n\"]\n",
      " ['nodeidB80' 'BinGNN.py' 'funcname' 80\n",
      "  '        # define optimizer, criterion.\\n']\n",
      " ['nodeidB81' 'BinGNN.py' 'funcname' 81\n",
      "  '        optimizer = torch.optim.Adam(model.parameters(), lr=_LEARNRATE_)\\n']\n",
      " ['nodeidB82' 'BinGNN.py' 'funcname' 82\n",
      "  '        criterion = torch.nn.CrossEntropyLoss()\\n']\n",
      " ['nodeidB83' 'BinGNN.py' 'funcname' 83\n",
      "  \"        print(f'[INFO] Optimizer settings:\\\\n{optimizer}')\\n\"]\n",
      " ['nodeidB84' 'BinGNN.py' 'funcname' 84\n",
      "  \"        print(f'[INFO] Criterion settings: {criterion}')\\n\"]\n",
      " ['nodeidB85' 'BinGNN.py' 'funcname' 85\n",
      "  \"        print(f'[INFO] Maximum epoch number: {_MAXEPOCHS_}')\\n\"]\n",
      " ['nodeidB86' 'BinGNN.py' 'funcname' 86\n",
      "  \"        print('[INFO] =============================================================')\\n\"]\n",
      " ['nodeidB87' 'BinGNN.py' 'funcname' 87 '        # train model.\\n']\n",
      " ['nodeidB88' 'BinGNN.py' 'funcname' 88\n",
      "  '        accList = [0]  # accuracy recorder.\\n']\n",
      " ['nodeidB89' 'BinGNN.py' 'funcname' 89\n",
      "  '        for epoch in range(1, _MAXEPOCHS_ + 1):\\n']\n",
      " ['nodeidB90' 'BinGNN.py' 'funcname' 90\n",
      "  '            # train model and evaluate model.\\n']\n",
      " ['nodeidB91' 'BinGNN.py' 'funcname' 91\n",
      "  '            model, loss = BGNNTrain(model, trainloader, optimizer=optimizer, criterion=criterion)\\n']\n",
      " ['nodeidB92' 'BinGNN.py' 'funcname' 92\n",
      "  '            trainAcc, trainPred, trainLabel = BGNNTest(model, trainloader)\\n']\n",
      " ['nodeidB93' 'BinGNN.py' 'funcname' 93\n",
      "  '            testAcc, testPred, testLabel = BGNNTest(model, testloader)\\n']\n",
      " ['nodeidB94' 'BinGNN.py' 'funcname' 94\n",
      "  \"            print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train Acc: {trainAcc:.4f}, Test Acc: {testAcc:.4f}')\\n\"]\n",
      " ['nodeidB95' 'BinGNN.py' 'funcname' 95\n",
      "  '            # save the best model.\\n']\n",
      " ['nodeidB96' 'BinGNN.py' 'funcname' 96\n",
      "  '            accList.append(testAcc)\\n']\n",
      " ['nodeidB97' 'BinGNN.py' 'funcname' 97\n",
      "  \"            SaveBestModel(accList, model, path=mdlsPath, modelname='BGNN', para=dim_features)\\n\"]\n",
      " ['nodeidB98' 'BinGNN.py' 'funcname' 98\n",
      "  '            # termination judgement.\\n']\n",
      " ['nodeidB99' 'BinGNN.py' 'funcname' 99\n",
      "  '            if (EndEpochLoop(accList, window=_WINDOWSIZ_, firstepoch=_FISTEPOCH_)): break\\n']\n",
      " ['nodeidB100' 'BinGNN.py' 'funcname' 100 '\\n']\n",
      " ['nodeidB101' 'BinGNN.py' 'funcname' 101\n",
      "  '    # evaluation with the best model.\\n']\n",
      " ['nodeidB102' 'BinGNN.py' 'funcname' 102\n",
      "  \"    model.load_state_dict(torch.load(mdlsPath + f'/model_BGNN_{dim_features}.pth'))\\n\"]\n",
      " ['nodeidB103' 'BinGNN.py' 'funcname' 103\n",
      "  '    testAcc, testPred, testLabel = BGNNTest(model, testloader)\\n']\n",
      " ['nodeidB104' 'BinGNN.py' 'funcname' 104\n",
      "  \"    OutputEval(testPred, testLabel, 'BGNN')\\n\"]\n",
      " ['nodeidB105' 'BinGNN.py' 'funcname' 105 '\\n']\n",
      " ['nodeidB106' 'BinGNN.py' 'funcname' 106 '    return model\\n']\n",
      " ['nodeidB107' 'BinGNN.py' 'funcname' 107 '\\n']\n",
      " ['nodeidB108' 'BinGNN.py' 'funcname' 108 \"if __name__ == '__main__':\\n\"]\n",
      " ['nodeidB109' 'BinGNN.py' 'funcname' 109 '    # sparse the arguments.\\n']\n",
      " ['nodeidB110' 'BinGNN.py' 'funcname' 110\n",
      "  '    # initialize the log file.\\n']\n",
      " ['nodeidB111' 'BinGNN.py' 'funcname' 111 \"    logfile = f'BinGNN.txt'\\n\"]\n",
      " ['nodeidB112' 'BinGNN.py' 'funcname' 112\n",
      "  '    if os.path.exists(os.path.join(logsPath, logfile)):\\n']\n",
      " ['nodeidB113' 'BinGNN.py' 'funcname' 113\n",
      "  '        os.remove(os.path.join(logsPath, logfile))\\n']\n",
      " ['nodeidB114' 'BinGNN.py' 'funcname' 114\n",
      "  '    elif not os.path.exists(logsPath):\\n']\n",
      " ['nodeidB115' 'BinGNN.py' 'funcname' 115\n",
      "  '        os.makedirs(logsPath)\\n']\n",
      " ['nodeidB116' 'BinGNN.py' 'funcname' 116\n",
      "  '    sys.stdout = Logger(os.path.join(logsPath, logfile))\\n']\n",
      " ['nodeidB117' 'BinGNN.py' 'funcname' 117\n",
      "  '    # set torch environment.\\n']\n",
      " ['nodeidB118' 'BinGNN.py' 'funcname' 118\n",
      "  \"    print('[INFO] CUDA Version: ' + (torch.version.cuda if torch.version.cuda else 'None'))\\n\"]\n",
      " ['nodeidB119' 'BinGNN.py' 'funcname' 119\n",
      "  \"    print('[INFO] PyTorch Version: ' + torch.__version__)\\n\"]\n",
      " ['nodeidB120' 'BinGNN.py' 'funcname' 120\n",
      "  \"    print('[INFO] Pytorch-Geometric Version: ' + tg_version)\\n\"]\n",
      " ['nodeidB121' 'BinGNN.py' 'funcname' 121 '    # main entrance.\\n']\n",
      " ['nodeidB122' 'BinGNN.py' 'funcname' 122 '    main()\\n']\n",
      " ['nodeidB123' 'BinGNN.py' 'funcname' 123 '    main()']]\n"
     ]
    }
   ],
   "source": [
    "# read graph of B.\n",
    "lines = open('b/BinGNN.py', 'r').readlines()\n",
    "nodesB = np.array([['nodeidB'+str(linenum+1), 'BinGNN.py', 'funcname', linenum+1, lines[linenum]] for linenum in range(len(lines))], dtype=object)\n",
    "print(nodesB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 25   1  25   1]\n",
      " [ 51   1  51   1]\n",
      " [ 55   1  55   2]\n",
      " [ 65   1  66   6]\n",
      " [ 95   1 101   1]\n",
      " [100   1 106   1]\n",
      " [115   0 122   1]]\n"
     ]
    }
   ],
   "source": [
    "# read the results in diff file.\n",
    "def ReadDiff(filename):\n",
    "    lines = open(filename, 'r').readlines()\n",
    "    pattern = r'@@ -(\\d+),*(\\d+)* \\+(\\d+),*(\\d+)* @@.*'\n",
    "    atLines = []\n",
    "    for line in lines:\n",
    "        contents = re.findall(pattern, line)\n",
    "        if len(contents):\n",
    "            atLines.append([int(c) if len(c) else 1 for c in contents[0]])\n",
    "    return np.array(atLines)\n",
    "\n",
    "atLines = ReadDiff('p/BinGNN.py.patch')\n",
    "print(atLines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-order A\n",
    "def ReOrder(nodes, atLines, version='A'):\n",
    "    if version not in ['A', 'B']:\n",
    "        print('[ERROR]')\n",
    "        return nodes\n",
    "    \n",
    "    acc = 0\n",
    "    for line in atLines:\n",
    "        threshold = line[0] if version == 'A' else line[2]\n",
    "        threshold += acc\n",
    "        diff = line[3] if version == 'A' else line[1]\n",
    "        acc += diff\n",
    "        # print(threshold, diff, acc)\n",
    "        for node in nodes:\n",
    "            if node[-2] > threshold:\n",
    "                node[-2] += diff\n",
    "            elif node[-2] == threshold and version == 'B':\n",
    "                node[-2] += diff\n",
    "    return nodes\n",
    "\n",
    "nodesA_new = ReOrder(nodesA, atLines, 'A')\n",
    "# print(nodesA)\n",
    "nodesB_new = ReOrder(nodesB, atLines, 'B')\n",
    "# print(nodesB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "- \n",
      "- \n",
      "-----------------------------\n",
      "1\n",
      "1 import os\n",
      "1 import os\n",
      "-----------------------------\n",
      "2\n",
      "2 import sys\n",
      "2 import sys\n",
      "-----------------------------\n",
      "3\n",
      "3 import time\n",
      "3 import time\n",
      "-----------------------------\n",
      "4\n",
      "4 import argparse\n",
      "4 import argparse\n",
      "-----------------------------\n",
      "5\n",
      "5 import numpy as np\n",
      "5 import numpy as np\n",
      "-----------------------------\n",
      "6\n",
      "6 import torch\n",
      "6 import torch\n",
      "-----------------------------\n",
      "7\n",
      "7 from torch_geometric import __version__ as tg_version\n",
      "7 from torch_geometric import __version__ as tg_version\n",
      "-----------------------------\n",
      "8\n",
      "8 from torch_geometric.loader import DataLoader\n",
      "8 from torch_geometric.loader import DataLoader\n",
      "-----------------------------\n",
      "9\n",
      "9 from libs.dataset import GetDataset\n",
      "9 from libs.dataset import GetDataset\n",
      "-----------------------------\n",
      "10\n",
      "10 # from libs.graphvis import VisualGraph, VisualGraphs\n",
      "10 # from libs.graphvis import VisualGraph, VisualGraphs\n",
      "-----------------------------\n",
      "11\n",
      "11 from libs.utils import TrainTestSplit, OutputEval, SaveBestModel, EndEpochLoop\n",
      "11 from libs.utils import TrainTestSplit, OutputEval, SaveBestModel, EndEpochLoop\n",
      "-----------------------------\n",
      "12\n",
      "12 from libs.nets.BGNN_sliced import BGNN, BGNNTrain, BGNNTest\n",
      "12 from libs.nets.BGNN_sliced import BGNN, BGNNTrain, BGNNTest\n",
      "-----------------------------\n",
      "13\n",
      "13 \n",
      "13 \n",
      "-----------------------------\n",
      "14\n",
      "14 # environment settings.\n",
      "14 # environment settings.\n",
      "-----------------------------\n",
      "15\n",
      "15 rootPath = './'\n",
      "15 rootPath = './'\n",
      "-----------------------------\n",
      "16\n",
      "16 tempPath = './'\n",
      "16 tempPath = './'\n",
      "-----------------------------\n",
      "17\n",
      "17 dataPath = rootPath + '/data_np2/'\n",
      "17 dataPath = rootPath + '/data_np2/'\n",
      "-----------------------------\n",
      "18\n",
      "18 logsPath = tempPath + '/logs/'\n",
      "18 logsPath = tempPath + '/logs/'\n",
      "-----------------------------\n",
      "19\n",
      "19 mdlsPath = tempPath + '/models/'\n",
      "19 mdlsPath = tempPath + '/models/'\n",
      "-----------------------------\n",
      "20\n",
      "20 # output parameters.\n",
      "20 # output parameters.\n",
      "-----------------------------\n",
      "21\n",
      "21 _DEBUG_  = 0    # 0: hide debug info. 1: show debug info.\n",
      "21 _DEBUG_  = 0    # 0: hide debug info. 1: show debug info.\n",
      "-----------------------------\n",
      "22\n",
      "22 _MODEL_  = 0    # 0: train new model. 1: use saved model.\n",
      "22 _MODEL_  = 0    # 0: train new model. 1: use saved model.\n",
      "-----------------------------\n",
      "23\n",
      "23 # hyper-parameters.\n",
      "23 # hyper-parameters.\n",
      "-----------------------------\n",
      "24\n",
      "24 _BATCHSIZE_ = 128\n",
      "24 _BATCHSIZE_ = 128\n",
      "-----------------------------\n",
      "25\n",
      "25 _MAXEPOCHS_ = 300\n",
      "- \n",
      "-----------------------------\n",
      "26\n",
      "- \n",
      "26 _MAXEPOCHS_ = 1000\n",
      "-----------------------------\n",
      "27\n",
      "27 _LEARNRATE_ = 0.01\n",
      "27 _LEARNRATE_ = 0.01\n",
      "-----------------------------\n",
      "28\n",
      "28 _TRAINRATE_ = 0.8\n",
      "28 _TRAINRATE_ = 0.8\n",
      "-----------------------------\n",
      "29\n",
      "29 _WINDOWSIZ_ = 0\n",
      "29 _WINDOWSIZ_ = 0\n",
      "-----------------------------\n",
      "30\n",
      "30 _FISTEPOCH_ = 0\n",
      "30 _FISTEPOCH_ = 0\n",
      "-----------------------------\n",
      "31\n",
      "31 \n",
      "31 \n",
      "-----------------------------\n",
      "32\n",
      "32 # global variable.\n",
      "32 # global variable.\n",
      "-----------------------------\n",
      "33\n",
      "33 start_time = time.time() #mark start time\n",
      "33 start_time = time.time() #mark start time\n",
      "-----------------------------\n",
      "34\n",
      "34 \n",
      "34 \n",
      "-----------------------------\n",
      "35\n",
      "35 # Logger: redirect the stream on screen and to file.\n",
      "35 # Logger: redirect the stream on screen and to file.\n",
      "-----------------------------\n",
      "36\n",
      "36 class Logger(object):\n",
      "36 class Logger(object):\n",
      "-----------------------------\n",
      "37\n",
      "37     def __init__(self, filename = \"log.txt\"):\n",
      "37     def __init__(self, filename = \"log.txt\"):\n",
      "-----------------------------\n",
      "38\n",
      "38         self.terminal = sys.stdout\n",
      "38         self.terminal = sys.stdout\n",
      "-----------------------------\n",
      "39\n",
      "39         self.log = open(filename, \"a\")\n",
      "39         self.log = open(filename, \"a\")\n",
      "-----------------------------\n",
      "40\n",
      "40     def write(self, message):\n",
      "40     def write(self, message):\n",
      "-----------------------------\n",
      "41\n",
      "41         self.terminal.write(message)\n",
      "41         self.terminal.write(message)\n",
      "-----------------------------\n",
      "42\n",
      "42         self.log.write(message)\n",
      "42         self.log.write(message)\n",
      "-----------------------------\n",
      "43\n",
      "43     def flush(self):\n",
      "43     def flush(self):\n",
      "-----------------------------\n",
      "44\n",
      "44         pass\n",
      "44         pass\n",
      "-----------------------------\n",
      "45\n",
      "45 \n",
      "45 \n",
      "-----------------------------\n",
      "46\n",
      "46 def RunTime():\n",
      "46 def RunTime():\n",
      "-----------------------------\n",
      "47\n",
      "47     pTime = ' [TIME: ' + str(round((time.time() - start_time), 2)) + ' sec]'\n",
      "47     pTime = ' [TIME: ' + str(round((time.time() - start_time), 2)) + ' sec]'\n",
      "-----------------------------\n",
      "48\n",
      "48     return pTime\n",
      "48     return pTime\n",
      "-----------------------------\n",
      "49\n",
      "49 \n",
      "49 \n",
      "-----------------------------\n",
      "50\n",
      "50 def main():\n",
      "50 def main():\n",
      "-----------------------------\n",
      "51\n",
      "51     # load the PatchCPG dataset.\n",
      "51     # load the PatchCPG dataset.\n",
      "-----------------------------\n",
      "52\n",
      "52     dataset = GetDataset(path=dataPath)  # get dataset from local dataset.\n",
      "- \n",
      "-----------------------------\n",
      "53\n",
      "- \n",
      "53     dataset, filelist = GetDataset(path=dataPath)  # get dataset from local dataset.\n",
      "-----------------------------\n",
      "54\n",
      "54     # VisualGraphs(dataset[0], state=1)\n",
      "54     # VisualGraphs(dataset[0], state=1)\n",
      "-----------------------------\n",
      "55\n",
      "55 \n",
      "55 \n",
      "-----------------------------\n",
      "56\n",
      "56     # divide train set and test set.\n",
      "56     # divide train set and test set.\n",
      "-----------------------------\n",
      "57\n",
      "57     dataTrain, dataTest = TrainTestSplit(dataset, train_size=0.8, allow_shuffle=False)\n",
      "- \n",
      "-----------------------------\n",
      "58\n",
      "- \n",
      "58     dataTrain, dataTest = TrainTestSplit(dataset, train_size=_TRAINRATE_, allow_shuffle=False)\n",
      "-----------------------------\n",
      "59\n",
      "- \n",
      "59     fileTrain, fileTest = filelist[0:len(dataTrain)], filelist[len(dataTrain):]\n",
      "-----------------------------\n",
      "60\n",
      "60     print(f'[INFO] Number of training graphs: {len(dataTrain)}')\n",
      "60     print(f'[INFO] Number of training graphs: {len(dataTrain)}')\n",
      "-----------------------------\n",
      "61\n",
      "61     print(f'[INFO] Number of test graphs: {len(dataTest)}')\n",
      "61     print(f'[INFO] Number of test graphs: {len(dataTest)}')\n",
      "-----------------------------\n",
      "62\n",
      "62     print(f'[INFO] Size of mini batch: {_BATCHSIZE_}')\n",
      "62     print(f'[INFO] Size of mini batch: {_BATCHSIZE_}')\n",
      "-----------------------------\n",
      "63\n",
      "63     print('[INFO] =============================================================')\n",
      "63     print('[INFO] =============================================================')\n",
      "-----------------------------\n",
      "64\n",
      "64     # get the train dataloader and test dataloader.\n",
      "64     # get the train dataloader and test dataloader.\n",
      "-----------------------------\n",
      "65\n",
      "65     trainloader = DataLoader(dataTrain, batch_size=_BATCHSIZE_, follow_batch=['x_s', 'x_t'], shuffle=False)\n",
      "65     trainloader = DataLoader(dataTrain, batch_size=_BATCHSIZE_, follow_batch=['x_s', 'x_t'], shuffle=False)\n",
      "-----------------------------\n",
      "66\n",
      "66     testloader = DataLoader(dataTest, batch_size=_BATCHSIZE_, follow_batch=['x_s', 'x_t'], shuffle=False)\n",
      "66     testloader = DataLoader(dataTest, batch_size=_BATCHSIZE_, follow_batch=['x_s', 'x_t'], shuffle=False)\n",
      "-----------------------------\n",
      "67\n",
      "67 \n",
      "67 \n",
      "-----------------------------\n",
      "68\n",
      "68     # demo for graph neural network.\n",
      "68     # demo for graph neural network.\n",
      "-----------------------------\n",
      "69\n",
      "69     demo_BinGNN(trainloader, testloader, dim_features=len(dataset[0].x_s[0]))\n",
      "- \n",
      "-----------------------------\n",
      "70\n",
      "- \n",
      "70     model = demo_BinGNN(trainloader, testloader, dim_features=len(dataset[0].x_s[0]))\n",
      "-----------------------------\n",
      "71\n",
      "- \n",
      "71     # output results on test data.\n",
      "-----------------------------\n",
      "72\n",
      "- \n",
      "72     _, testPred, _ = BGNNTest(model, testloader)\n",
      "-----------------------------\n",
      "73\n",
      "- \n",
      "73     with open(logsPath + 'TestResults.txt', 'w') as f:\n",
      "-----------------------------\n",
      "74\n",
      "- \n",
      "74         for i in range(len(fileTest)):\n",
      "-----------------------------\n",
      "75\n",
      "- \n",
      "75             f.write(fileTest[i] + ',' + str(testPred[i]) + '\\n')\n",
      "-----------------------------\n",
      "76\n",
      "76 \n",
      "76 \n",
      "-----------------------------\n",
      "77\n",
      "77     return\n",
      "77     return\n",
      "-----------------------------\n",
      "78\n",
      "78 \n",
      "78 \n",
      "-----------------------------\n",
      "79\n",
      "79 def demo_BinGNN(trainloader, testloader, dim_features):\n",
      "79 def demo_BinGNN(trainloader, testloader, dim_features):\n",
      "-----------------------------\n",
      "80\n",
      "80     device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "80     device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "-----------------------------\n",
      "81\n",
      "81     model = BGNN(num_node_features=dim_features)\n",
      "81     model = BGNN(num_node_features=dim_features)\n",
      "-----------------------------\n",
      "82\n",
      "82 \n",
      "82 \n",
      "-----------------------------\n",
      "83\n",
      "83     if not (_MODEL_ and os.path.exists(mdlsPath + f'/model_BGNN_{dim_features}.pth')):\n",
      "83     if not (_MODEL_ and os.path.exists(mdlsPath + f'/model_BGNN_{dim_features}.pth')):\n",
      "-----------------------------\n",
      "84\n",
      "84         # define optimizer, criterion.\n",
      "84         # define optimizer, criterion.\n",
      "-----------------------------\n",
      "85\n",
      "85         optimizer = torch.optim.Adam(model.parameters(), lr=_LEARNRATE_)\n",
      "85         optimizer = torch.optim.Adam(model.parameters(), lr=_LEARNRATE_)\n",
      "-----------------------------\n",
      "86\n",
      "86         criterion = torch.nn.CrossEntropyLoss()\n",
      "86         criterion = torch.nn.CrossEntropyLoss()\n",
      "-----------------------------\n",
      "87\n",
      "87         print(f'[INFO] Optimizer settings:\\n{optimizer}')\n",
      "87         print(f'[INFO] Optimizer settings:\\n{optimizer}')\n",
      "-----------------------------\n",
      "88\n",
      "88         print(f'[INFO] Criterion settings: {criterion}')\n",
      "88         print(f'[INFO] Criterion settings: {criterion}')\n",
      "-----------------------------\n",
      "89\n",
      "89         print(f'[INFO] Maximum epoch number: {_MAXEPOCHS_}')\n",
      "89         print(f'[INFO] Maximum epoch number: {_MAXEPOCHS_}')\n",
      "-----------------------------\n",
      "90\n",
      "90         print('[INFO] =============================================================')\n",
      "90         print('[INFO] =============================================================')\n",
      "-----------------------------\n",
      "91\n",
      "91         # train model.\n",
      "91         # train model.\n",
      "-----------------------------\n",
      "92\n",
      "92         accList = [0]  # accuracy recorder.\n",
      "92         accList = [0]  # accuracy recorder.\n",
      "-----------------------------\n",
      "93\n",
      "93         for epoch in range(1, _MAXEPOCHS_ + 1):\n",
      "93         for epoch in range(1, _MAXEPOCHS_ + 1):\n",
      "-----------------------------\n",
      "94\n",
      "94             # train model and evaluate model.\n",
      "94             # train model and evaluate model.\n",
      "-----------------------------\n",
      "95\n",
      "95             model, loss = BGNNTrain(model, trainloader, optimizer=optimizer, criterion=criterion)\n",
      "95             model, loss = BGNNTrain(model, trainloader, optimizer=optimizer, criterion=criterion)\n",
      "-----------------------------\n",
      "96\n",
      "96             trainAcc, trainPred, trainLabel = BGNNTest(model, trainloader)\n",
      "96             trainAcc, trainPred, trainLabel = BGNNTest(model, trainloader)\n",
      "-----------------------------\n",
      "97\n",
      "97             testAcc, testPred, testLabel = BGNNTest(model, testloader)\n",
      "97             testAcc, testPred, testLabel = BGNNTest(model, testloader)\n",
      "-----------------------------\n",
      "98\n",
      "98             print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train Acc: {trainAcc:.4f}, Test Acc: {testAcc:.4f}')\n",
      "98             print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train Acc: {trainAcc:.4f}, Test Acc: {testAcc:.4f}')\n",
      "-----------------------------\n",
      "99\n",
      "99             # save the best model.\n",
      "99             # save the best model.\n",
      "-----------------------------\n",
      "100\n",
      "100             accList.append(testAcc)\n",
      "100             accList.append(testAcc)\n",
      "-----------------------------\n",
      "101\n",
      "101             SaveBestModel(accList, model, path=mdlsPath, modelname='BGNN', para=dim_features)\n",
      "101             SaveBestModel(accList, model, path=mdlsPath, modelname='BGNN', para=dim_features)\n",
      "-----------------------------\n",
      "102\n",
      "102             # termination judgement.\n",
      "102             # termination judgement.\n",
      "-----------------------------\n",
      "103\n",
      "103             if (EndEpochLoop(accList, window=_WINDOWSIZ_, firstepoch=_FISTEPOCH_)): break\n",
      "103             if (EndEpochLoop(accList, window=_WINDOWSIZ_, firstepoch=_FISTEPOCH_)): break\n",
      "-----------------------------\n",
      "104\n",
      "104 \n",
      "104 \n",
      "-----------------------------\n",
      "105\n",
      "105         # evaluation with the best model.\n",
      "- \n",
      "-----------------------------\n",
      "106\n",
      "- \n",
      "106     # evaluation with the best model.\n",
      "-----------------------------\n",
      "107\n",
      "107     model.load_state_dict(torch.load(mdlsPath + f'/model_BGNN_{dim_features}.pth'))\n",
      "107     model.load_state_dict(torch.load(mdlsPath + f'/model_BGNN_{dim_features}.pth'))\n",
      "-----------------------------\n",
      "108\n",
      "108     testAcc, testPred, testLabel = BGNNTest(model, testloader)\n",
      "108     testAcc, testPred, testLabel = BGNNTest(model, testloader)\n",
      "-----------------------------\n",
      "109\n",
      "109     OutputEval(testPred, testLabel, 'BGNN')\n",
      "109     OutputEval(testPred, testLabel, 'BGNN')\n",
      "-----------------------------\n",
      "110\n",
      "110 \n",
      "110 \n",
      "-----------------------------\n",
      "111\n",
      "111     return \n",
      "- \n",
      "-----------------------------\n",
      "112\n",
      "- \n",
      "112     return model\n",
      "-----------------------------\n",
      "113\n",
      "113 \n",
      "113 \n",
      "-----------------------------\n",
      "114\n",
      "114 if __name__ == '__main__':\n",
      "114 if __name__ == '__main__':\n",
      "-----------------------------\n",
      "115\n",
      "115     # sparse the arguments.\n",
      "115     # sparse the arguments.\n",
      "-----------------------------\n",
      "116\n",
      "116     # initialize the log file.\n",
      "116     # initialize the log file.\n",
      "-----------------------------\n",
      "117\n",
      "117     logfile = f'BinGNN.txt'\n",
      "117     logfile = f'BinGNN.txt'\n",
      "-----------------------------\n",
      "118\n",
      "118     if os.path.exists(os.path.join(logsPath, logfile)):\n",
      "118     if os.path.exists(os.path.join(logsPath, logfile)):\n",
      "-----------------------------\n",
      "119\n",
      "119         os.remove(os.path.join(logsPath, logfile))\n",
      "119         os.remove(os.path.join(logsPath, logfile))\n",
      "-----------------------------\n",
      "120\n",
      "120     elif not os.path.exists(logsPath):\n",
      "120     elif not os.path.exists(logsPath):\n",
      "-----------------------------\n",
      "121\n",
      "121         os.makedirs(logsPath)\n",
      "121         os.makedirs(logsPath)\n",
      "-----------------------------\n",
      "122\n",
      "122     sys.stdout = Logger(os.path.join(logsPath, logfile))\n",
      "122     sys.stdout = Logger(os.path.join(logsPath, logfile))\n",
      "-----------------------------\n",
      "123\n",
      "123     # set torch environment.\n",
      "123     # set torch environment.\n",
      "-----------------------------\n",
      "124\n",
      "124     print('[INFO] CUDA Version: ' + (torch.version.cuda if torch.version.cuda else 'None'))\n",
      "124     print('[INFO] CUDA Version: ' + (torch.version.cuda if torch.version.cuda else 'None'))\n",
      "-----------------------------\n",
      "125\n",
      "125     print('[INFO] PyTorch Version: ' + torch.__version__)\n",
      "125     print('[INFO] PyTorch Version: ' + torch.__version__)\n",
      "-----------------------------\n",
      "126\n",
      "126     print('[INFO] Pytorch-Geometric Version: ' + tg_version)\n",
      "126     print('[INFO] Pytorch-Geometric Version: ' + tg_version)\n",
      "-----------------------------\n",
      "127\n",
      "127     # main entrance.\n",
      "127     # main entrance.\n",
      "-----------------------------\n",
      "128\n",
      "- \n",
      "128     main()\n",
      "-----------------------------\n",
      "129\n",
      "129     main()129     main()-----------------------------\n"
     ]
    }
   ],
   "source": [
    "# test.\n",
    "i, j = 0, 0\n",
    "for linenum in range(130):\n",
    "    lA, lB = '-', '-'\n",
    "    codeA, codeB = '\\n', '\\n'\n",
    "    if i < len(nodesA_new) and nodesA_new[i][-2] == linenum:\n",
    "        lA = nodesA_new[i][-2]\n",
    "        codeA = nodesA_new[i][-1]\n",
    "        i += 1\n",
    "    if j < len(nodesB_new) and nodesB_new[j][-2] == linenum:\n",
    "        lB = nodesB_new[j][-2]\n",
    "        codeB = nodesB_new[j][-1]\n",
    "        j += 1\n",
    "    print(linenum)\n",
    "    print(lA, codeA, end='')\n",
    "    print(lB, codeB, end='')\n",
    "    print('-----------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paimon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d48c547015b97257b9c3afed803319ec6bc86f1b079aa3d8d80b151a0d7e6a1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
